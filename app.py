import streamlit as st
from PIL import Image
import numpy as np
import cv2
import math
from datetime import datetime

# ==============================================================================
# [WES Final Ver 4.3] Forensic Mode (Anti-Forgery)
# í•µì‹¬ ê¸°ëŠ¥: 'Sê¸‰ ëª¨ì‚¬í’ˆ'ì„ ì¡ê¸° ìœ„í•œ ì´ˆì •ë°€ ê²€ì¦(Forensic) ì˜µì…˜ ì¶”ê°€
# ì¼ë°˜ ëª¨ë“œëŠ” ìœ ì—°í•˜ê²Œ, ê°ë³„ ëª¨ë“œëŠ” ì˜¤ì°¨ 1.0 ë¯¸ë§Œìœ¼ë¡œ ì¹¼ê°™ì´ ì°¨ë‹¨
# ==============================================================================

def resize_optimized(img_array, max_dim):
    h, w = img_array.shape[:2]
    if max(h, w) > max_dim:
        scale = max_dim / max(h, w)
        new_w, new_h = int(w * scale), int(h * scale)
        return cv2.resize(img_array, (new_w, new_h), interpolation=cv2.INTER_AREA)
    return img_array

def calculate_angles(pt1, pt2, pt3):
    def length(p1, p2):
        return math.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)
    a, b, c = length(pt2, pt3), length(pt1, pt3), length(pt1, pt2)
    if a == 0 or b == 0 or c == 0: return [0, 0, 0]
    try:
        val_A = (b**2 + c**2 - a**2) / (2 * b * c)
        val_B = (a**2 + c**2 - b**2) / (2 * a * c)
        val_A = max(-1.0, min(1.0, val_A))
        val_B = max(-1.0, min(1.0, val_B))
        angle_A = math.degrees(math.acos(val_A))
        angle_B = math.degrees(math.acos(val_B))
        angle_C = 180 - angle_A - angle_B
    except ValueError: return [0, 0, 0]
    return sorted([angle_A, angle_B, angle_C])

def verify_geometry(kp1, kp2, good_matches, strict_mode=False):
    """
    strict_mode=Trueì¼ ê²½ìš°: ëª¨ì‚¬í’ˆ ê°ë³„ì„ ìœ„í•´ í—ˆìš© ì˜¤ì°¨ë¥¼ ê·¹ë‹¨ì ìœ¼ë¡œ ì¤„ì„
    """
    pts1 = [kp1[m.queryIdx].pt for m in good_matches]
    pts2 = [kp2[m.trainIdx].pt for m in good_matches]
    final_indices = set()
    
    # 1. RANSAC ì„ê³„ê°’ ì¡°ì •
    # ì¼ë°˜: 4.0 (ìœ ì—°í•¨) / ê°ë³„: 1.0 (í”½ì…€ ë‹¨ìœ„ ì¼ì¹˜ ìš”êµ¬)
    ransac_thresh = 1.0 if strict_mode else 4.0
    
    if len(good_matches) >= 4:
        src_pts = np.float32(pts1).reshape(-1, 1, 2)
        dst_pts = np.float32(pts2).reshape(-1, 1, 2)
        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, ransac_thresh)
        if M is None: return []
        matches_mask = mask.ravel().tolist()
        global_correct_matches = [good_matches[i] for i in range(len(good_matches)) if matches_mask[i]]
    else: return []

    # 2. ê°ë„ ê²€ì¦ ì„ê³„ê°’ ì¡°ì •
    # ì¼ë°˜: 3.0ë„ í—ˆìš© / ê°ë³„: 1.0ë„ í—ˆìš© (ì‚¬ëŒ ì†ìœ¼ë¡œëŠ” ì ˆëŒ€ ëª» ë§ì¶¤)
    angle_thresh = 1.0 if strict_mode else 3.0
    
    check_list = global_correct_matches[:300]
    for i in range(len(check_list) - 2):
        m1, m2, m3 = check_list[i], check_list[i+1], check_list[i+2]
        p1, p2, p3 = kp1[m1.queryIdx].pt, kp1[m2.queryIdx].pt, kp1[m3.queryIdx].pt
        q1, q2, q3 = kp2[m1.trainIdx].pt, kp2[m2.trainIdx].pt, kp2[m3.trainIdx].pt
        ang1 = calculate_angles(p1, p2, p3)
        ang2 = calculate_angles(q1, q2, q3)
        diff = sum([abs(a - b) for a, b in zip(ang1, ang2)])
        
        if diff < angle_thresh:
            final_indices.add(m1); final_indices.add(m2); final_indices.add(m3)
            
    return list(final_indices)

def match_art_forensic(img1_pil, img2_pil, strict_mode):
    # í•´ìƒë„: ê°ë³„ ëª¨ë“œì—ì„œëŠ” 2K (2000px), ì¼ë°˜ì€ 1280pxë„ ì¶©ë¶„í•˜ì§€ë§Œ ì•ˆì „í•˜ê²Œ 2000 í†µì¼
    img1_cv = resize_optimized(np.array(img1_pil), max_dim=2000)
    img2_cv = resize_optimized(np.array(img2_pil), max_dim=2000)
    
    gray1 = cv2.cvtColor(img1_cv, cv2.COLOR_RGB2GRAY)
    gray2 = cv2.cvtColor(img2_cv, cv2.COLOR_RGB2GRAY)
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
    gray1 = clahe.apply(gray1); gray2 = clahe.apply(gray2)

    sift = cv2.SIFT_create(nfeatures=10000, contrastThreshold=0.03, edgeThreshold=10)
    kp1, des1 = sift.detectAndCompute(gray1, None)
    if des1 is None or len(des1) < 10: return False, 0, 0, None, "íŠ¹ì§•ì  ë¶€ì¡±"

    scales = [0.5, 1.0] 
    flann = cv2.FlannBasedMatcher(dict(algorithm=1, trees=5), dict(checks=40))
    
    best_count = 0; best_ratio = 0.0; best_img = None; best_scale = 1.0

    for scale in scales:
        try:
            if scale == 1.0: resized_gray2 = gray2; resized_kp2_img = img2_cv
            else:
                new_w = int(gray2.shape[1] * scale); new_h = int(gray2.shape[0] * scale)
                if new_w < 50 or new_h < 50: continue
                resized_gray2 = cv2.resize(gray2, (new_w, new_h), interpolation=cv2.INTER_AREA)
                resized_kp2_img = cv2.resize(img2_cv, (new_w, new_h))

            kp2, des2 = sift.detectAndCompute(resized_gray2, None)
            total_target_kps = len(kp2)
            if des2 is None or total_target_kps < 10: continue

            matches = flann.knnMatch(des1, des2, k=2)
            # ê°ë³„ ëª¨ë“œì¼ ë•ŒëŠ” Ratio testë„ 0.7ë¡œ ê°•í™” (ì•„ì£¼ ë˜‘ê°™ì€ ê²ƒë§Œ í—ˆìš©)
            ratio_thresh = 0.7 if strict_mode else 0.75
            good_matches = [m for m, n in matches if m.distance < ratio_thresh * n.distance]
            
            # [í•µì‹¬] strict_mode ì „ë‹¬
            final_matches = verify_geometry(kp1, kp2, good_matches, strict_mode)
            current_count = len(final_matches)
            current_ratio = (current_count / total_target_kps) * 100 if total_target_kps > 0 else 0

            if current_count > best_count:
                best_count = current_count; best_ratio = current_ratio; best_scale = scale
                res_img = cv2.drawMatches(img1_cv, kp1, resized_kp2_img, kp2, final_matches, None, flags=2, matchColor=(0, 255, 0))
                best_img = cv2.cvtColor(res_img, cv2.COLOR_BGR2RGB)
                if best_ratio > 15.0 and best_count > 200: break
        except: continue

    is_genuine = False
    
    if strict_mode:
        # [ê°ë³„ ëª¨ë“œ] ì ìˆ˜ê°€ íŒ ê¹ì´ë¯€ë¡œ ê¸°ì¤€ì„ ì¡°ê¸ˆ ë‚®ê²Œ ì¡ë˜, í†µê³¼í–ˆë‹¤ëŠ” ê²ƒ ìì²´ê°€ ëŒ€ë‹¨í•œ ê²ƒì„
        if best_count >= 50 and best_ratio >= 3.0: is_genuine = True
    else:
        # [ì¼ë°˜ ëª¨ë“œ] ê¸°ì¡´ Ver 4.2 ë¡œì§ (ìœ ì—°í•¨)
        if best_count >= 80: is_genuine = True
        elif best_count >= 15 and best_ratio >= 10.0: is_genuine = True
    
    if best_ratio < 1.0: is_genuine = False # ì•ˆì „ì¥ì¹˜

    mode_str = "Sê¸‰ ëª¨ì‚¬í’ˆ ê°ë³„" if strict_mode else "ì¼ë°˜ ê²€ì¦"
    msg = f"ğŸ›¡ï¸ [{mode_str}] {best_count}ì  (ë§¤ì¹­ë¥  {best_ratio:.1f}%)"
    return is_genuine, best_count, best_ratio, best_img, msg

# --- ê³ ì† ì—”ì§„ (ìœ ì§€) ---
def match_fast_rapid(img1_pil, img2_pil):
    img1_cv = np.array(img1_pil); img2_cv = np.array(img2_pil)
    img1_small = resize_optimized(img1_cv, max_dim=640)
    img2_small = resize_optimized(img2_cv, max_dim=640)
    gray1 = cv2.cvtColor(img1_small, cv2.COLOR_RGB2GRAY)
    gray2 = cv2.cvtColor(img2_small, cv2.COLOR_RGB2GRAY)
    sift = cv2.SIFT_create(nfeatures=1000) 
    kp1, des1 = sift.detectAndCompute(gray1, None)
    kp2, des2 = sift.detectAndCompute(gray2, None)
    if des1 is None or des2 is None or len(des2) < 5: return False, 0, 0, None, "íŠ¹ì§•ì  ë¶€ì¡±"
    flann = cv2.FlannBasedMatcher(dict(algorithm=1, trees=5), dict(checks=30))
    matches = flann.knnMatch(des1, des2, k=2)
    good_matches = [m for m, n in matches if m.distance < 0.75 * n.distance]
    final_matches = []
    if len(good_matches) >= 4:
        src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)
        dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)
        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)
        if M is not None:
            matches_mask = mask.ravel().tolist()
            final_matches = [good_matches[i] for i in range(len(good_matches)) if matches_mask[i]]
    count = len(final_matches)
    ratio = (count / len(kp2)) * 100 if len(kp2) > 0 else 0
    res_img = cv2.drawMatches(img1_small, kp1, img2_small, kp2, final_matches, None, flags=2, matchColor=(0, 255, 0))
    res_img_rgb = cv2.cvtColor(res_img, cv2.COLOR_BGR2RGB)
    is_genuine = (count >= 10) and (ratio >= 15.0)
    msg = f"âš¡ ë§¤ì¹­ë¥ : {ratio:.1f}% ({count}ì )"
    return is_genuine, count, ratio, res_img_rgb, msg

# UI
if 'artworks' not in st.session_state: st.session_state['artworks'] = [] 
if 'cars' not in st.session_state: st.session_state['cars'] = []
if 'objects' not in st.session_state: st.session_state['objects'] = []

st.set_page_config(page_title="WES Final Ver 4.3", layout="wide")
st.title("ğŸ“± WES í†µí•© í”Œë«í¼ [Final Ver 4.3]")
st.caption("ì‹œìŠ¤í…œ: Forensic Mode Added (ì •ë°€ ëª¨ì‚¬í’ˆ ëŒ€ì‘)")

tab1, tab2, tab3 = st.tabs(["ğŸ¨ A. ì§„í’ˆ ê±°ë˜", "ğŸš— B. ìŠ¤ë§ˆíŠ¸ ì£¼ì°¨", "ğŸ§¸ C. ì‚¬ë¬¼/ë¯¸ì•„ ì°¾ê¸°"])

with tab1:
    st.header("ğŸ¨ ë¯¸ìˆ í’ˆ ì§„í’ˆ ì¸ì¦")
    c1, c2 = st.columns(2)
    with c1:
        with st.form("art_reg"):
            up = st.file_uploader("ì›ë³¸ ë“±ë¡", key="a_up")
            name = st.text_input("ì‘í’ˆëª…/ì†Œìœ ì")
            if st.form_submit_button("ë“±ë¡") and up:
                st.session_state['artworks'].append({"image": Image.open(up), "name": name})
                st.success(f"'{name}' ë“±ë¡ ì™„ë£Œ")
    with c2:
        ver = st.file_uploader("ê²€ì¦", key="a_ver")
        # [New] ê°ë³„ ëª¨ë“œ ì²´í¬ë°•ìŠ¤
        strict_mode = st.checkbox("ğŸ•µï¸ Sê¸‰ ëª¨ì‚¬í’ˆ ê°ë³„ (ì´ˆì •ë°€ ëª¨ë“œ)", help="ì²´í¬ ì‹œ ì˜¤ì°¨ ë²”ìœ„ë¥¼ 1.0 ë¯¸ë§Œìœ¼ë¡œ ì¤„ì…ë‹ˆë‹¤. ì‚¬ì§„ì„ ë°˜ë“¯í•˜ê²Œ ì°ì–´ì•¼ í•©ë‹ˆë‹¤.")
        
        if ver and st.button("ğŸ” ê²€ì¦ ì‹œì‘"):
            t = Image.open(ver)
            st.image(t, width=200)
            with st.spinner("ë¶„ì„ ì¤‘..."):
                bm=None; mm=0; br=0; bi=None; bmsg=""
                for art in st.session_state['artworks']:
                    # strict_mode ê°’ ì „ë‹¬
                    res = match_art_forensic(art['image'], t, strict_mode)
                    if res[1] > mm: mm=res[1]; br=res[2]; bm=art; bi=res[3]; bmsg=res[4]
                if bm and res[0]: 
                    st.success(f"ğŸ‰ ì§„í’ˆì…ë‹ˆë‹¤! (ì›ë³¸: {bm['name']})")
                    st.info(bmsg); st.image(bi, use_container_width=True)
                else: 
                    st.error("ğŸš¨ ê°€í’ˆ(ë˜ëŠ” ëª¨ì‚¬í’ˆ)ì…ë‹ˆë‹¤.")
                    if mm > 0: st.warning(f"ìœ ì‚¬ì  {mm}ê°œ - êµ¬ì¡°ì  ë¶ˆì¼ì¹˜ ({bmsg})")

with tab2:
    st.header("ğŸš— ìŠ¤ë§ˆíŠ¸ ì£¼ì°¨ ê´€ì œ")
    c3, c4 = st.columns(2)
    with c3:
        with st.form("car_reg"):
            up = st.file_uploader("ì…ì°¨ ì°¨ëŸ‰", key="c_up")
            no = st.text_input("ì°¨ëŸ‰ ë²ˆí˜¸")
            if st.form_submit_button("ì…ì°¨") and up:
                st.session_state['cars'].append({"image": Image.open(up), "no": no, "time": datetime.now()})
                st.success(f"ì°¨ëŸ‰ '{no}' ì…ì°¨ ì™„ë£Œ")
    with c4:
        ver = st.file_uploader("ì¶œì°¨ ì¸ì‹", key="c_ver")
        if ver and st.button("âš¡ ì •ì‚° ìš”ì²­"):
            t = Image.open(ver)
            bm=None; mm=0; br=0; bi=None; bmsg=""
            for car in st.session_state['cars']:
                res = match_fast_rapid(car['image'], t)
                if res[1] > mm: mm=res[1]; br=res[2]; bm=car; bi=res[3]; bmsg=res[4]
            if bm and res[0]:
                duration = datetime.now() - bm['time']
                fee = (duration.seconds // 60 // 10) * 1000 
                st.success(f"âœ… ì°¨ëŸ‰ ì¸ì‹: {bm['no']}")
                st.info(f"ì£¼ì°¨ ì‹œê°„: {duration.seconds//60}ë¶„ / ìš”ê¸ˆ: {fee:,}ì›")
                st.image(bi, use_container_width=True)
            else: st.error("ğŸš« ì¸ì‹ ì‹¤íŒ¨"); st.warning(bmsg)

with tab3:
    st.header("ğŸ§¸ ì‚¬ë¬¼/ë¯¸ì•„ ì°¾ê¸°")
    c5, c6 = st.columns(2)
    with c5:
        with st.form("obj_reg"):
            up = st.file_uploader("ëŒ€ìƒ ë“±ë¡", key="o_up")
            info = st.text_input("ì´ë¦„/ì—°ë½ì²˜")
            if st.form_submit_button("ë“±ë¡") and up:
                st.session_state['objects'].append({"image": Image.open(up), "info": info})
                st.success(f"'{info}' ë“±ë¡ ì™„ë£Œ")
    with c6:
        ver = st.file_uploader("ë°œê²¬ë¬¼ ì´¬ì˜", key="o_ver")
        if ver and st.button("âš¡ ë³´í˜¸ì ì°¾ê¸°"):
            t = Image.open(ver)
            bm=None; mm=0; br=0; bi=None; bmsg=""
            for obj in st.session_state['objects']:
                res = match_fast_rapid(obj['image'], t)
                if res[1] > mm: mm=res[1]; br=res[2]; bm=obj; bi=res[3]; bmsg=res[4]
            if bm and res[0]:
                st.success(f"âœ… í™•ì¸ë¨!")
                st.info(f"ë³´í˜¸ì ì •ë³´: {bm['info']}")
                st.image(bi, use_container_width=True)
            else: st.error("ğŸš« ì •ë³´ ì—†ìŒ"); st.warning(bmsg)
